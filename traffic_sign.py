# -*- coding: utf-8 -*-
"""Traffic Sign.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oyin0quD9Ib6AcIPnm9rEpCbMLHnhWpE
"""

!git clone https://bitbucket.org/jadslim/german-traffic-signs

!ls german-traffic-signs

import numpy as np
import matplotlib.pyplot as plt
import keras
from keras.models import Sequential,Model
from keras.layers import Dense,Flatten,Dropout
from keras.layers.convolutional import Conv2D, MaxPooling2D
from keras.optimizers import Adam
from keras.utils.np_utils import to_categorical
from keras.preprocessing.image import ImageDataGenerator
import random
import pickle
import pandas as pd
import cv2
from PIL import Image
import requests

np.random.seed(0)

with open('german-traffic-signs/train.p','rb') as f:
  train_data = pickle.load(f)
with open('german-traffic-signs/valid.p','rb') as f:
  val_data = pickle.load(f)
with open('german-traffic-signs/test.p','rb') as f:
  test_data = pickle.load(f)

X_train = train_data['features']
y_train = train_data['labels']

X_val = val_data['features']
y_val = val_data['labels']

X_test = test_data['features']
y_test = test_data['labels']





print(X_train.shape,X_val.shape,X_test.shape)

assert(X_train.shape[0] == y_train.shape[0]),'The no. of images is not equal to the no. of labels'
assert(X_test.shape[0] == y_test.shape[0]),'The no. of images is not equal to the no. of labels'
assert(X_val.shape[0] == y_val.shape[0]),'The no. of images is not equal to the no. of labels'
assert(X_train.shape[1:] == (32,32,3)),'The dimensions of the image  are not equal to 32 x 32 x 3'
assert(X_val.shape[1:] == (32,32,3)),'The dimensions of the image  are not equal to 32 x 32 x 3'
assert(X_test.shape[1:] == (32,32,3)),'The dimensions of the image  are not equal to 32 x 32 x 3'

data = pd.read_csv('german-traffic-signs/signnames.csv')
# print(type(data),data)
#x_selected = X_train[y_train == 31]
#print(x_selected[3,:,:,0])

num_of_samples =  []
cols = 5
num_classes = 43

fig,axs = plt.subplots(num_classes,cols,figsize=(5,50))
fig.tight_layout()

for i in range(cols):
  for j, row in data.iterrows():
    x_selected = X_train[y_train == j]
    axs[j][i].imshow(x_selected[random.randint(0,len(x_selected)-1),:,:],cmap = plt.get_cmap('gray'))
    axs[j][i].axis('off')
    if i==2:
      axs[j][i].set_title(str(j) + '-' + row['SignName'])
      num_of_samples.append(len(x_selected))

print(num_of_samples)
plt.figure(figsize=(12, 4))
plt.bar(range(0, num_classes), num_of_samples)
plt.title("Distribution of the training dataset")
plt.xlabel("Class number")
plt.ylabel("Number of images")

plt.show()

def grayscale(img):
  gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
  return gray
  
def equalize(gray):   
  img = cv2.equalizeHist(gray) # it will only take gray scale images and distribute the intensity over whole and increases the brightness of the images
  return img

def preprocessing(img):
  img =  grayscale(img)
  img = equalize(img)
  img = img/255  # this  is called normalisation to make data b/w 0-1
  return img

X_train = np.array(list(map(preprocessing,X_train)))
X_val = np.array(list(map(preprocessing,X_val)))
X_test = np.array(list(map(preprocessing,X_test)))

X_train = X_train.reshape(34799, 32, 32,1)
X_val = X_val.reshape(4410, 32, 32,1)
X_test = X_test.reshape(12630, 32, 32,1)

datagen = ImageDataGenerator(width_shift_range=0.1,
                  height_shift_range=0.1,
                  zoom_range=0.2,
                  shear_range=0.1,
                  rotation_range=10)

datagen.fit(X_train)

batches = datagen.flow(X_train,y_train,batch_size = 20)
X_batch,y_batch = next(batches)

fig,axs = plt.subplots(1,15,figsize=(20,5))
fig.tight_layout()

for i in range(15):
  axs[i].imshow(X_batch[i].reshape(32,32))
  axs[i].axis('off')

# One Hot Encoding for labels
y_train = to_categorical(y_train,43)
y_val = to_categorical(y_val,43)
y_test = to_categorical(y_test,43)



# CONVOLUTIONAL NEURAL NETWORK MODEL LE-NET

def modified_net():
  model = Sequential()
  model.add(Conv2D(60,(5,5),input_shape=(32,32,1),activation='relu'))
  model.add(Conv2D(60,(5,5),activation='relu'))
  model.add(MaxPooling2D(pool_size = (2,2)))
  
  model.add(Conv2D(30,(3,3),activation='relu'))
  model.add(Conv2D(30,(3,3),activation='relu'))
  model.add(MaxPooling2D(pool_size=(2,2)))
  #model.add(Dropout(0.5))
  
  model.add(Flatten())
  model.add(Dense(units = 500,activation='relu'))
  model.add(Dropout(0.5))
  model.add(Dense(num_classes,activation ='softmax'))
  # COMPILE MODEL
  model.compile(Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])
  
  return model



model = modified_net()
print(model.summary())

history = model.fit_generator(datagen.flow(X_train,y_train,batch_size=50),steps_per_epoch=2000,epochs=10,verbose=1,shuffle=1,validation_data=(X_val,y_val))

plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.legend(['Training','Validation'])
plt.xlabel('epochs')
plt.title('Accuracy')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['Training','Validation'])
plt.xlabel('epochs')
plt.title('Loss')
plt.show()

score = model.evaluate(X_test,y_test)
print('Test Score :',score[0],'Test Accuracy :',score[1])

#fetch data
#url = 'https://previews.123rf.com/images/bwylezich/bwylezich1608/bwylezich160800375/64914157-german-road-sign-slippery-road.jpg'
#url ='https://c8.alamy.com/comp/G667W0/road-sign-speed-limit-30-kmh-zone-passau-bavaria-germany-G667W0.jpg'
url = 'https://c8.alamy.com/comp/A0RX23/cars-and-automobiles-must-turn-left-ahead-sign-A0RX23.jpg'
#url = 'https://c8.alamy.com/comp/J2MRAJ/german-road-sign-bicycles-crossing-J2MRAJ.jpg'
#url = 'https://previews.123rf.com/images/pejo/pejo0907/pejo090700003/5155701-german-traffic-sign-no-205-give-way.jpg'
response = requests.get(url,stream=True)
img = Image.open(response.raw)
plt.imshow(img,cmap = plt.get_cmap('gray'))

# Preprocessing image
img = np.asarray(img)
img = cv2.resize(img,(32,32))
img = preprocessing(img)
plt.imshow(img,cmap = plt.get_cmap('gray'))

img = np.reshape(img,(1,32,32,1))

predict = model.predict_classes(img)
print("predict :",str(predict),data['SignName'][predict])

